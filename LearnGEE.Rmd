---
title: "Learn GEE"
author: "Joseph Holler"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
```

This learning exercise is based upon Hanley et al (2003), <https://doi.org/10.1093/aje/kwf215>

## Learn GEE

-   Avoid treating observations from the same "cluster" as independent
-   Examples of "clusters" include:
    -   repeated measurements for the same person over time
    -   surveys of multiple members of the same household
    -   multiple observations in the same geographic region?
-   Some approaches to resolving this problem include
    -   discarding repeated observations
    -   including repeated observations but calculating statistical power based on the number of clusters rather than the number of observations
-   How can you use all the data points while also not exaggerating your statistical power?
-   GEE uses "weighted combinations of observations to extract the appropriate amount of information from correlated data"

Elements of notation:

|        Variables        | Parameter Symbol | Statistic Symbol |
|:-----------------------:|:----------------:|:----------------:|
|        household        |       $h$        |                  |
|          mean           |      $\mu$       |  $\overline{y}$  |
|   standard deviation    |     $\delta$     |                  |
|       proportion        |       $P$        |       $p$        |
| regression coefficient  |       $B$        |       $b$        |
| correlation coefficient |       $R$        |       $r$        |

## Variance of Weighted Sum

1.  Make a correlation matrix out of the variable and its weights
2.  For each row/column combination, find: row-weight \* column-weight \* row-δ \* column-δ \* row-column-$R$
3.  Sum the products from step 2

-   If there is no correlation, then off-diagonal R values are 0, and the weighted variance is simply the sum of squared weights and variances.
-   standard error of a mean is: $\mu$ / $\sqrt{n}$ ... and this is what you get if there is no correlation and equal weights in the sample
-   standard error of an estimate is basically the standard deviation of it...
-   if data is correlated, the standard error increases (since you're no longer multiplying by 0 off-diagonal)

## What if some observations are clustered?

-   three children: 1 single child and 2 siblings
-   optimal weight for observations correlated within clusters is: 1 / (1 + $R$($k$-1)) where $k$ is the size of the cluster
-   evidence that this is the optimal weight is shown in Figure 3 and described as provable with calculus on pg 368
-   as correlation within clusters approaches 1, the effective sample size of the study decreases to the number of clusters. This make sense, as perfect correlation with clusters means that a cluster is effectively a single observation

## Estimating the mean and correlation

First, create sample data and calculate a matrix to use as a mask for the off-diagonal products for calculating variance.
Also calculate the denominators for variance and covariance calculations.

```{r create-sample-data}
# create simple data 
val <- c(15, 13, 10, 9, 8)
grp <- c(1, 1, 2, 2, 2)
fig4data <- data.frame(val, grp)
rm(val, grp)

n <- length(fig4data$val)
m <- matrix(nrow = n, ncol = n)

fig4data <- fig4data %>% 
  group_by(grp) %>% 
  mutate(k = n(), w = 1 / n) %>% 
  ungroup()

for (x in 1:(n-1)){
  for(y in (x+1):n){
    if(fig4data[x,"grp"] == fig4data[y,"grp"]){
      m[x,y] <- 1
    }
  }
}

var_d <- n - 1
covar_d <- sum(m, na.rm = TRUE) - 1
```

Here is a process for the estimation:

-   start with assumption of no correlation $R$ = 0
-   calculate estimate of $\mu$ based on $R$ = 0
-   calculate new estimate $r$ of $R$
-   Repeat until you reach convergence (no more change in $R$)

```{r fig4iterate}
r_prior <- 1
r <- 0
iteration <- 1

while(abs(r - r_prior) > 0.001){
  # new weight is 1 / (1 + (k-1)r)
  fig4data <- fig4data %>% mutate(w = 1 / (1 + r * (fig4data$k - 1)))
  
  # weighted mean
  mu <- sum(fig4data$val * fig4data$w) / sum(fig4data$w)
  
  resid <- fig4data$val - mu
  
  # estimated variance is sum of diagonal products divided by n(5) - 1
  v <- sum(resid^2) / var_d
  
  # estimated covariance is sum of off-diagonal products divided by n(4) - 1
  c <- sum(outer(resid, resid, "*") * m, na.rm = TRUE) / covar_d
  
  # estimated correlation is estimated covariance / estimated variance
  r_prior <- r
  r <- c / v

  cat("iteration:", iteration, "\n",
      "weighted mean:", mu, "\n",
      "variance:", v, "\n",
      "covariance:", c, "\n",
      "correlation:", r, "\n",
      "effective sample size:", sum(fig4data$w), "\n\n"
      )
  
  iteration <- iteration + 1
}
```

### Discussion notes

-   For regression, you would use find the within-cluster correlation of regression residuals to re-define weights. Therefore, I wonder if the geepack algorithm can output the residuals or even the final set of weights?
-   Hierarchical & multilevel models estimate between-cluster variation and incorporate this into standard errors, while GEE does the opposite---estimating within-cluster correlation.
